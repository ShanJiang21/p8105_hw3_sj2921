---
title: "p8105_hw3_sj2921"
author: "Shan Jiang"
date: "10/5/2018"
output: github_document
---
## Problem 1
```{r}
# Set the graph properties(theme, color and size) for ggplot
library(ggplot2)
library(readxl)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```
* Import the data
```{r echo=FALSE,results='hide'}
library(tidyverse)
library(p8105.datasets)
# Import the BFRSS data, exclude variables and format the data by using appropriate names.
brfss_df <- 
    brfss_smart2010 %>% 
    janitor::clean_names() %>% 
    filter(response == "Excellent"  | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") 

```
* structure data: Response indicating the proportion of subjects with each response
```{r}
# Convert response to build a factor; Specify the levels of response_vector
response <- 
  factor(brfss_df$response, 
  levels <- (c("Excellent","Very Good", "Good", "Fair", "Poor")))


```
##### Questions
* 1.In 2002,  CT, MT, NH, NM, OR, TN, UT were observed at 7 locations.
```{r}
 brfss_df %>% 
  group_by(locationabbr) %>% 
  distinct(locationdesc) %>% 
  summarise(n = n()) %>% 
  filter(n == 7)
```
* 2.Make a spaghetti plot showing the number of observations in each state from 2002 to 2010
```{r}
location <- brfss_df %>% 
  group_by(locationabbr, year) %>% 
  summarise(n = n()) 

ggplot(location, aes(x = year, y = n)) +
  geom_line(alpha = .3, aes(group = locationabbr)) +
  geom_point(alpha = .3) +
  labs(
    title = "Number of observations in each state(n) from 2002 to 2010",
    x = "Year",
    y = "Number of observations in each state(n)",
    caption = "Data from the BRFSS package"
  ) + scale_color_hue(name = "locationabbr", 
                  h = c(200, 300))
```
* 3. Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.
```{r}
 brfss_df %>% 
  filter(locationabbr == "NY" & response == "Excellent") %>%
  filter(year == "2002" | year == "2006" | year == "2010") %>% 
  group_by(year) %>% 
  summarise(mean_ex = mean(data_value),
            sd_ex = sd(data_value)) 
```
* 4.1 For each year and state, compute the average proportion in each response category (taking the average across locations in a state). 
```{r}
panel <- brfss_df %>%
  group_by(locationabbr, year) %>% 
  summarise(n = n(),
            avg_pro = mean(data_value))
```
* 4.2 Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.
```{r}
ggplot(panel, aes(x = year, y = avg_pro )) +
  geom_point()


```

# problem 2

##### The dataset cleaning and summarizing 

**Instacart Dataset description**

1. There are **1384617 observations** and **15** variables in the dataset. The dataset is a long dataset using the order_id and user_id as main keys. 
```{r}
# 21 departments: summary
instacart %>% 
  janitor::clean_names() %>% 
  group_by(department) %>% 
  summarize(n = n()) %>% 
  mutate(dep_ranking = min_rank(desc(n))) %>% 
  filter(dep_ranking > 20 | dep_ranking < 4)
```

2. We know that there are in total 21 departments. According to the ranking for no.of orders in each department, the 3 top-ranked department are **produce, dairy eggs and snacks**. The produce department has received 409087 orders which are the double of the second-ranked dairy eggs. The least popular department is **bulk**, which only has 1359 orders.

```{r}
# The top-3 buyers for placing the most orders
instacart %>% 
  janitor::clean_names() %>% 
  group_by(user_id) %>% 
  summarize(n = n()) %>% 
  mutate(user_ranking = min_rank(desc(n))) %>% 
  filter(user_ranking < 3)
```
3. The one who has the highest purchasing power among users are the two **user_id:149753, user_id:197541**.Both of them have 80 orders and they have maintained a high reorder rate. 
```{r}
# The most popular products
instacart %>% 
  janitor::clean_names() %>% 
  group_by(product_name) %>% 
  summarize(n = n()) %>% 
  mutate(pro_ranking = min_rank(desc(n))) %>% 
  filter(pro_ranking < 3)
```

4. The most popular product are **Bananas** which appeared in 18726 orders. Bag of Organic Bananas, following as the second, they appeared in 15480 orders, so the supply of bananas should be addressed.

Questions
-
1. How many aisles are there, and which aisles are the most items ordered from?
```{r}

```
2.


3.


# problem 3
* NY NOAA data
1.load the data
```{r}
# Import the ny_noaa data, exclude variables and format the data by using appropriate names.
ny_noaa <- 
    ny_noaa %>% 
    janitor::clean_names() 
View(ny_noaa)
```
2.a short description of the dataset
The ny_noaa data set contains 7 variables and 2595176 observation value.

- some key variables include: 
* prcp: The daily precipitation volume in the unique location(id as key). 
* snow: The daily snow volume in the unique location(id as key)
* snwd: South to North Water diversion in the specific date.

_ missing data is an issue: 

```{r}

```

